<!DOCTYPE html>

<html lang="en-US" prefix="og: http://opg.me/ns#">
  <head>
    <meta charset="UTF-8" />

    <meta name="title" property="og:title" content="Apex" />

    <meta
      name="description"
      property="og:description"
      content="Crato is an open source framework for small web applications to easily deploy a centralized logging solution that maintains ownership of data"
    />

    <meta name="type" property="og:type" content="website" />

    <meta
      name="url"
      property="og:url"
      content="https://crato-logging.github.io/"
    />

    <meta
      name="image"
      property="og:image"
      content="images/logos/apex-logo.png"
    />

    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta
      name="author"
      content="Faazil Shaikh, Kurth O'Connor, Alex Soloviev"
    />

    <title>APEX</title>

    <link rel="apple-touch-icon" sizes="180x180" href="/images/icons/favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/images/icons/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/images/icons/favicons/favicon-16x16.png">
    <link rel="manifest" href="/images/icons/favicons/site.webmanifest">
    <link rel="mask-icon" href="/images/icons/favicons/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="/images/icons/favicons/favicon.ico">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-config" content="/images/icons/favicons/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">

    <!-- <style>reset</style> -->

    <link rel="stylesheet" href="stylesheets/reset.css" />

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/styles/gruvbox-dark.min.css"
      charset="utf-8"
    />

    <!-- <style></style> -->

    <link rel="stylesheet" href="stylesheets/main.css" />

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>

    <!-- <script></script> -->

    <script src="javascripts/application.js"></script>

    <style>
    </style>
  </head>

  <body>
    <div class="logo-links">
      <p id="apex-logo">APEX</p>

      <a href="https://github.com/apex-api-proxy" target="_blank">
        <img
          src="images/logos/github_black.png"
          alt="github logo"
          id="github-logo"
        />
      </a>
    </div>
    <a id="toTop-link" href="#" target="_blank">
      <img
        src="images/logos/back-to-top.png"
        alt="Back to top"
        id="toTop-logo"
      />
    </a>
    <nav id="site-navigation">
      <ul>
        <li>
          <a href="#home" id="home-link">HOME</a>
        </li>

        <li>
          <a href="#case-study" id="case-study-link">CASE STUDY</a>

          <nav id="case-study-mobile">
            <ul></ul>
          </nav>
        </li>

        <li>
          <a href="#our-team" id="our-team-link">OUR TEAM</a>
        </li>
      </ul>
    </nav>

    <header id="home">
      <h1>
        <img src="images/logos/apex-logo.png" alt="Apex logo" />

        <p>API proxy for microservices</p>
      </h1>
    </header>

    <section class="integration">
      <div class="box">
        <img src="images/diagrams/apex-architecture-2.png" alt="best practices" />
      </div>

      <article class="box">
        <div class="text-box">
          <h1>Manage service-to-service traffic</h1>

          <p>
            Centralized logging, tracing, and custom retry logic without managing client libraries in microservices.
          </p>

          <!-- <a class="button" href="#case-study">Learn More</a> -->
        </div>
      </article>
    </section>

    <section class="integration">
      <article class="box">
        <div class="text-box">
          <h1>Easy To Deploy</h1>

          <p>
            Get started with a few simple commands.
          </p>

          <!-- <a class="button" href="#case-study">Learn More</a> -->
        </div>
      </article>
      <div class="box">
        <img
          id="banner-deploy"
          src="images/diagrams/gifs/apex_deploy_2.gif"
          class="softened"
          alt="Deploy Apex proxy with a few commands"
        />
      </div>
    </section>

    <main>
      <section id="case-study">
        <h1>Apex: API proxy for microservices</h1>
        <p class="subheader">
          One place to log and control service-to-service traffic
        </p>

        <div id="side-nav">
          <img src="images/logos/apex-logo.png" alt="Apex logo" />
        </div>

        <nav>
          <ul></ul>
        </nav>

        <h2 id="introduction">1) Introduction</h2>

        <div class="img-wrapper">
          <img
            src="images/diagrams/gifs/apex_add_service.gif"
            alt="Monolith with multiple databases"
          />
        </div>

        <p>
          Apex is an API proxy for microservices. It provides one place to log and control service-to-service traffic.
        </p>

        <p>
          Apex is designed for small teams that have just begun migrating from a monolith to a microservices architecture. While microservices bring many benefits, chief among them greater scalability, they also bring a host of new challenges by relying on the network for service-to-service communication. As network communication is unreliable and has latency, faults become more likely to occur, leading teams to have to spend more time diagnosing network-related faults, and writing pre-emptive fault-handling logic within each service.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/gifs/apex_query_logs.gif"
            alt="Monolith with multiple databases"
          />
        </div>

        <p>
          Some current solutions exist to help teams perform these tasks faster. Client libraries can be imported into each service’s code to automate networking concerns, an API gateway can be inserted in front of all services to handle incoming traffic, and for large systems, a service mesh is often deployed to abstract away networking concerns from services altogether. These are all valid solutions, designed for different users, and with their own set of trade-offs.
        </p>

        <p>
          For a small team running their first few microservices, however, none of the existing solutions provide the right set of trade-offs: optimized for service-to-service traffic, and ease of deployment and operation, over high availability and scalability. These are the trade-offs that underpinned Apex’s design.
        </p>

        <p>
          With Apex, a user can view the logs for all service-to-service traffic by querying just one table, while grouping all requests and responses that belong to the same workflow. They can also define and update traffic rules such as the number of times to retry a request in one configuration store.
        </p>

        <h2 id="microservices">2) Microservices</h2>

        <p>
          To understand how Apex makes it easier to work with microservices, it is important to first understand what microservices are. This, in turn, requires understanding that the microservices architecture is a choice, the other choice being, of course, a monolith.
        </p>

        <h3>2.1) Microservices are an alternative to monoliths</h3>

        <p>
          In a monolithic architecture, there is typically just one application server (the ‘monolith’) that holds all the business logic. In some cases, this application server alone is already sufficient to serve an application to a user (e.g. a website with just static HTML). More likely though, the application will also generate some user data that must be persisted, and so the monolithic application server will also transfer data to and from a database server.
        </p>

        <div class="img-wrapper">
          <img src="images/diagrams/monolilth.jpg" alt="Monolith" />
        </div>

        <p>
          Consider the above example of a monolithic system that serves an e-commerce store to users. The business logic in the app server can be organized into classes or modules, or more generally, ‘subsystems’, that encapsulate related functionality e.g. manipulating customer data, checking and updating inventory, generating shipping instructions. These subsystems can each expose an interface of methods, or more generally ‘behaviors’, that can be invoked by each other to facilitate communication between them.
        </p>

        <p>
          As method or function calls take place within the same running process in memory, they are reliable and very fast, usually returning within a few milliseconds.
        </p>

        <div class="img-wrapper">
          <img src="images/diagrams/method_calls.jpg" alt="Method calls" />
        </div>

        <p>
          Another possible monolithic architecture is to further separate the
          data store into multiple database servers. For example, the
          <code>customers</code> subsystem and the <code>orders</code> subsystem can be connected to
          separate database servers, if that is deemed to be e.g. more flexible,
          or more scalable.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/monolith_with_multiple_databases.jpg"
            alt="Monolith with multiple databases"
          />
        </div>

        <p>
          A simple analogy for a monolithic application is a small business run by just one owner. The owner has to do everything - sales and marketing, procurement, operations, finance, IT. There may be one central log book that keeps track of all business data, or the owner could use several ‘persistent data stores’ in parallel e.g. CRM system for sales data, accounting software for financial data, ERP system for inventory data, pen and paper for tax filings.
        </p>

        <h3>2.2) Microservices architecture organizes business logic into multiple independently deployed ‘services’</h3>

        <p>
          In a microservices architecture, subsystems are decoupled even further. Now, each subsystem is deployed independently to its own app server as a standalone ‘application’, or ‘service’, and the current best practice is for every service to have its own database.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/2.2) subsystems.png"
            alt="Subsystems can exist in monoliths and as microservices"
          />
        </div>

        <p>
          The other crucial difference is that subsystems now communicate over the network via HTTP requests, rather than through in-process method invocations. So for example, if our `orders` service needs to create a new shipment, it might do this by sending a `POST` request to the `/shipments` endpoint of the `shipping` service, and attaching any other relevant information in the request body.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/2.2) over the network.png"
            alt="Microservices communicate over the network via http requests and responses"
          />
        </div>

        <p>
          Going with the same analogy of a small business, the microservices architecture is comparable to a small team of several members (services) who each specialize in one function. For example, these could include a salesperson, a marketer, an operations manager, accountant/bookkeeper and an IT manager. Now, function-to-function communication no longer happens in the owner’s head (in-process); instead, different team members must communicate with each other in person, on the phone or by email (over the network) to get things done.
        </p>

        <p>
          As we shall see, the use of the network for communication between subsystems is the key enabler for many of the benefits of the microservices architecture, but also the main culprit behind many of its drawbacks.
        </p>

        <h3>2.3) Microservices enable subsystems to be developed, deployed and scaled independently from each other</h3>

        <p>
          The benefits of the microservices architecture become apparent as systems, and the teams that develop and operate them, grow beyond a certain scale.
        </p>

        <p>
          The network boundaries between services free them from having to use the same technology stack. As long as each service maintains a stable network interface, or API, for other services talking to it, it is free to choose the language or framework that is most optimal for implementing its business logic.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/2.3) different technologies.png"
            alt="Microservices can use different technologies as long as their APIs remain stable"
          />
        </div>

        <p>
          Where microservices really shine, though, is the option to <a href="https://martinfowler.com/articles/microservices.html">deploy subsystems independently of each other</a>. With subsystems now deployed to independent services that each have a smaller scope, redeploying any one subsystem incurs less overhead and so it becomes practical to redeploy each service more frequently.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/2.2) independently redeployed.png"
            alt="Each microservice can be independently redeployed as long as their APIs remain stable"
          />
        </div>

        <p>
          More concretely, in our e-commerce example app, as soon as a feature in the `orders` service is ready, `orders` can be redeployed - as long as `orders`’s API remains the same before and after the deployment, other services need not even know that a redeployment took place. On the other hand, if the `notifications` logic rarely changes, then that service can simply continue to operate untouched. By minimising the scope of each redeployment, we not only eliminate unnecessary engineering, but are also able to ship new features faster and reap the business benefits sooner.
        </p>

        <p>
          A similar efficiency is found in scaling a microservices architecture. If our `orders` service is the first to reach its capacity, then we can simply upgrade `orders` to a more powerful server or deploy more replicas of `orders`, without having to also replicate every other service. Yet again, as long as the replicated `orders` service retains the same API before and after scaling, the other services can continue to operate in the same way as though nothing happened. The result is fewer large-scale system-wide redeployments and higher utilisation of provisioned resources, leading to savings in engineering time and costs.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/2.3) independently scaled.png"
            alt="Each microservice can be independently scaled as long as their APIs remain stable"
          />
        </div>

        <h2 id="microservices">3) Challenges with microservices</h2>

        <p>
          We have seen how the network boundaries between microservices are what give them many benefits over a monolith. The network, however, comes with baggage, and relying heavily on it to communicate between subsystems introduces an entire new dimension of challenges.
        </p>

        <h3>3.1) Microservices communicate over the network, which is unreliable and has latency</h3>

        <p>
          Recall that in a monolith, subsystems are simply classes or modules that communicate through method invocations within the same process in memory. In contrast, in a microservices architecture, equivalent calls are now sent between services using HTTP requests and responses over the network.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/3.1) method calls fast.png"
            alt="Method calls are fast; network hops are relatively slow"
          />
        </div>

        <p>
          As any sufficiently heavy user of the internet will have experienced, the network is unreliable and has latency. That is, networks can disconnect for any number of reasons, and network traffic can sometimes take a long time to reach its destination. Even though in production, services are likely deployed to state-of-the-art data centers run by cloud providers, network faults still can and do occur.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/3.1) dropped from network.png"
            alt="Requests or responses can be dropped from the network"
          />
        </div>

        <p>
          Such faults introduce a whole new class of problems for developers - not only do they have to ensure their service code is bug-free, now they also have to diagnose unexpected network faults, and add logic to service code that preempts network faults by providing compensating behaviors (e.g. displaying a ‘network down’ page to users, or retrying the same request a few seconds later).
        </p>

        <h3>3.2) Diagnosing network faults can be cumbersome</h3>

        <p>
          Diagnosing a network fault can be especially difficult when a single workflow passes through multiple services. Consider a user placing an order on our e-commerce example app, and suppose the <code>orders</code> service needs to first update inventory in <code>inventory</code>, then create a shipment in <code>shipping</code>. This one workflow involves 3 services with at least 3 network hops between them. If the order placement eventually fails, what caused that to happen?
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/3.2) where did the fault.png"
            alt="Finding where the network fault occurred can be difficult"
          />
        </div>

        <p>
          To find out, a developer would have to trace the user’s initial `POST` request through the entire system. Since each service generates its own logs, the developer would have to first access `orders`’s logs, track down the request that failed, follow the request to the next service (in our case, the `inventory` service), access `customers`’s logs, and so on, until they pinpoint the exact request that failed. This can be a laborious and slow process.
        </p>

        <h3>3.3) Defining similar fault-handling logic within libraries in service code slows down updates to the logic</h3>

        <p>
          Other times, a network fault may be totally random, and a request should simply be retried again. But how long should the requesting service wait before retrying again? How many times should it retry before giving up? If too soon or too many, then all the retries could overwhelm the responding service. Such logic must be defined thoughtfully.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/3.3) retry failed.png"
            alt="Retrying failed requests requires thoughtful logic"
          />
        </div>

        <p>
          The next question becomes: where should all this logic be defined? For some teams, the first answer to this question is in HTTP client libraries that are imported into each service’s code. So if the <code>orders</code> service is written in Ruby, then it would <code>require</code> a gem that provides a configurable client for making HTTP requests to other services. Another service written in Node might <code>import</code> a similar package into its code.
        </p>

        <p>
          Often, these libraries can also handle logging, as well as other networking and infrastructure concerns, such as caching, rate-limiting, authentication etc.
        </p>

        <p>
          Teams with more resources may go further, by having each service’s owner write a client library for every other service that calls it. This is already common practice when working with popular external APIs; for example, Stripe provides dozens of <a href="https://stripe.com/docs/libraries">official and third-party libraries</a> in different languages that abstract away the logic for calling its APIs. In the same way, in a large team each service’s owner may be tasked with writing a new client library for every requesting service that uses a different language.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/3.3) a new shipping client.png"
            alt="A new shipping client library for every language"
          />
        </div>

        <p>
          Needless to say, this solution becomes less and less manageable as the number of services grows. Every time a new service is built in a new language, every other service owner must write a new client library in that language. More critically, updating fault-handling logic now incurs a great deal of repetitive work. Suppose the CTO wishes to update the global defaults for the retry logic; developers would now have to update the code in multiple client libraries in every service, then carefully coordinate each service’s redeployment. The greater the number of services, the slower this process becomes.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/3.3) as more services.png"
            alt="As more services are added, client libraries can get out of hand"
          />
        </div>

        <h2>4) Existing solutions</h2>

        <p>
          With microservices becoming increasingly popular, a number of solutions have emerged to help teams overcome these challenges. Here we explain how two of these solutions - the API gateway and the service mesh - compare with each other.
        </p>

        <p>
          Both of these solutions in fact share the same building block - a proxy server.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/4) building block.png"
            alt="As more services are added, client libraries can get out of hand"
          />
        </div>

        <h3>4.0) Proxy server - the building block</h3>

        <p>
          A proxy is simply a server that sits on the path of network traffic between two communicating machines, and intercepts all their requests and responses. These machines could represent a client sending a request to another server, or for our purposes, two internal services communicating within the same architecture.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/4.0) proxy server can intercept.png"
            alt="As more services are added, client libraries can get out of hand"
          />
        </div>

        <p>
          In the above diagram, `orders` does not send an HTTP request directly to `shipping`; instead, it addresses its request to a host belonging to `proxy` (i.e. `proxy.com`). In order for `proxy` to know that `orders` actually wants to send its request to `shipping`, `orders` must specify `shipping`’s host (i.e. `shipping.com`) in another part of the request e.g. in the `Host` header value.
        </p>

        <p>
          When <code>proxy</code> receives a response back from <code>shipping</code>, it simply forwards the same response back to <code>orders</code>.
        </p>

        <h3>4.1) API gateway</h3>

        <h4>4.1.1) An API gateway is a proxy server that intercepts all incoming requests from outside the system</h4>

        <p>
          At its core, an API gateway is simply a proxy server (more precisely, a ‘reverse proxy’). When used with microservices, one of its primary functions is to provide a stable API to clients and route client requests to the appropriate service.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/4.1.1) API gateway proxies.png"
            alt="An API gateway proxies all incoming requests into a system"
          />
        </div>

        <p>
          It is certainly possible to do without an API gateway. In such an architecture, whenever the client sends a request, it must already know which service to send the request to, and also the host and port of that service. This tightly couples the client with internal services, such that any newly added services, or updates to existing service APIs, must be deployed at the same time as updates in the client code [add reference: NGINX on API gateways]. Such an architecture can be difficult to manage, as clients cannot always be relied upon to update immediately (e.g. mobile apps cannot be easily forced to update); even if they can, doing so would still incur additional engineering that could be avoided.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/4.1.1) without an API gateway.png"
            alt="Without an API gateway, a client must know the host port and path of every service it needs to call"
          />
        </div>

        <p>
          With an API gateway, developers are largely free to update internal services while still providing a stable API to clients.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/4.1.1) an API gateway provides.png"
            alt="An API gateway provides a stable API for clients, even if services are upgraded, replicated, or moved internally"
          />
        </div>

        <p>
          In addition to routing requests, the API gateway also provides one place to handle many concerns that are shared between services, such as authentication, caching, rate-limiting, load-balancing and monitoring.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/4.1.1) also provides.png"
            alt="An API gateway als provides one place to manage other networking concerns"
          />
        </div>

        <p>
          In a way, an API gateway can be thought of as a receptionist at a large company. Any visitor does not necessarily have to know which employees are present in advance, or how different teams work together to complete specific tasks. Instead, they simply speak with the receptionist, who then decides, based on the visitor’s identity and stated purpose, which company employee to notify, and/or what access to grant to the visitor.
        </p>

        <h4>4.1.2) An API gateway is designed for client-server, not service-to-service, traffic</h4>

        <p>
          Let us revisit the challenges that were described back in section 3 [add anchor link]: 1) diagnosing faults in workflows that span multiple microservices, and 2) managing fault-handling logic that is similar across services.
        </p>

        <p>
          If the API gateway already provides one place to manage networking concerns, perhaps it is already a sufficient solution to these challenges? For example, instead of deploying it as a ‘front proxy’ that sits in front of all services, we could deploy it in a different pattern than it was intended for - as a proxy that sits between services internally. Would this not already provide the one place where a log of all service-to-service requests and responses can be aggregated, and fault-handling logic like retries can be defined?
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/4.1.2) Could we just.png"
            alt="Could we just deploy an API gateway internally between services?"
          />
        </div>

        <p>
          In theory, this is certainly possible, but in practice, existing API gateway solutions are not ideal options for this.
        </p>

        <blockquote>
          Optimized to handle [client-server] traffic at the edge of the data center, the API gateway ... is inefficient for the large volume of [service-to-service] traffic in distributed microservices environments: it has a large footprint (to maximize the solution’s appeal to customers with a wide range of use cases), can’t be containerized, and the constant communication with the database and a configuration server adds latency.
          <cite><a href="https://www.nginx.com/blog/do-you-really-need-different-kinds-of-api-gateways-hint-no/">- NGINX, the maker of the popular open-source NGINX load balancer and web server</a></cite>
        </blockquote>

        <p>
          In short, although the API gateway looks close to the solution we need, existing solutions on the market come built-in with many extra features that are designed for client-server traffic, making them a poor fit for managing service-to-service traffic.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/4.1.2) API gateways features.png"
            alt="Could we just deploy an API gateway internally between services?"
          />
        </div>

        <p>
          That is not to say that a solution like an API gateway is completely out of the question. As we shall see in section 5 [add anchor link], the API gateway pattern was a major source of inspiration for Apex’s solution.
        </p>





--------------------

        <div class="img-wrapper">
          <img
            src="images/diagrams/scaling_a_monolith.jpg"
            alt="Scaling a monolith"
          />
        </div>

        <p>
          As a system scales even further, however, the monolith’s strengths can
          begin to hold it back.
        </p>

        <h3>3.1) Microservices communicate over the network, which is unreliable and has latency</h3>

        <p class="strikethrough">
          While having all business logic in one codebase initially made the
          system easier to understand, this is no longer true when the codebase
          balloons to millions of lines of code. As new developers are brought
          on for just one or two subsystems, they will have little choice but to
          parse through the rest of the codebase as they make new changes and
          work to debug then pre-empt unexpected ripple effects. This lengthens
          the time taken for new developers to become productive, and the
          problem only gets worse as the system inevitably scales to ever more
          lines of code.
        </p>

        <p>
          Having just one codebase places constraints on technology choices. If
          the app was initially implemented in Ruby, but now finds itself in
          need of data analysis capabilities that are already available in the
          Python ecosystem, it is not possible to just import a Python package.
          The only alternative, if no equivalent gems exist in the Ruby
          ecosystem, would be to build them in-house. This costs extra
          development time.
        </p>

        <p>
          The monolith’s simple deployment can turn into slower deployment. One
          codebase may be simpler to deploy, but it also means that any updates,
          however small, require the entire app to be redeployed. As each
          redeploy costs a certain amount of overhead, it is typically
          impractical to redeploy too frequently. Usually, teams gravitate
          toward a ‘release train’<sup><a href="#footnote-1">1</a></sup
          > [<a
          href=>https://www.thoughtworks.com/radar/techniques/release-train</a>],
          where redeploys are done on a fixed schedule, and any feature that is
          ready earlier - and any business benefits that might come with it -
          must wait until the next redeploy.
        </p>

        <p>
          A similar inflexibility is seen when scaling out a monolith. Recall
          our e-commerce example app - it is expected that each subsystem will
          reach its capacity limits at a different pace. Suppose <code>orders</code> is the
          first subsystem to flirt with its capacity limit, at which point its
          developer decides to replicate the subsystem rather than upgrade to a
          more powerful server. The only way to do this would be to replicate
          the entire app i.e. deploy another replica of the entire app,
          containing every one of its subsystems and not just <code>orders</code>, to
          another server - even if none of the other subsystems are operating at
          or near capacity. That is not an efficient use of compute resources.
        </p>

        <div class="img-wrapper">
          <img
            src="images/diagrams/replicating_monolith.jpg"
            alt="Replicating a monolith"
          />
        </div>

        <h3>
          2.3) Microservices architecture organizes business logic into multiple
          independently deployed ‘services’
        </h3>

        <h2 id="future-plans">8 Future Plans</h2>

        <ul>
          <li>Additional visualization/monitoring integration</li>
          <li>
            Security
            <ul>
              <li>option for LAN</li>
              <li>client-server communication with TLS</li>
            </ul>
          </li>
          <li>Compression option for large messages</li>
          <li>Add robust & automated testing</li>
        </ul>

        <section id="footnotes">
          <h2 id="references">9 References</h2>

          <ol>
            <li id="footnote-1">
              <a href="https://www.thoughtworks.com/radar/techniques/release-train" target="_blank"
                >https://www.thoughtworks.com/radar/techniques/release-train</a
              >
            </li>
          </ol>
          <!--

          <h5>9.2 Resources</h5>

          <ol>

            <li><a

                href="https://www.manning.com/books/serverless-architectures-on-aws"

                target="_blank">Serverless Architecture on AWS</a>

            </li>

          </ul>

-->
        </section>
      </section>
    </main>

    <section id="our-team">
      <h1>Our Team</h1>

      <p>
        We are looking for opportunities. If you liked what you saw and want to
        talk more, please reach out!
      </p>

      <ul>
        <li class="individual">
          <img src="https://avatars1.githubusercontent.com/u/10019150?s=460&u=916f068a14b51f7f173c26943a966a49642bbdc4&v=4" alt="Derick Gross" />

          <h3>Derick Gross</h3>

          <p>New York, NY</p>

          <ul class="social-icons">
            <li>
              <a href="mailto:derick.gross@gmail.com" target="">
                <img src="images/icons/email_icon.png" alt="email" />
              </a>
            </li>

            <li>
              <a href="https://github.com/derickgross" target="_blank">
                <img src="images/icons/website_icon.png" alt="website" />
              </a>
            </li>

            <li>
              <a href="https://www.linkedin.com/in/derickgross/" target="_blank">
                <img src="images/icons/linked_in_icon.png" alt="linkedin" />
              </a>
            </li>
          </ul>
        </li>

        <li class="individual">
          <img
            src="https://media-exp1.licdn.com/dms/image/C5603AQEKm4855aKamA/profile-displayphoto-shrink_800_800/0?e=1593043200&v=beta&t=h5U5iPhDEFm0YBZ5r7-STq7x6h85KKLZ1w_iIPbTs9U"
            alt="Kelvin Wong"
          />

          <h3>Kelvin Wong</h3>

          <p>London, UK</p>

          <ul class="social-icons">
            <li>
              <a href="mailto:kjhwong@gmail.com" target="">
                <img src="images/icons/email_icon.png" alt="email" />
              </a>
            </li>

            <li>
              <a href="https://github.com/kelvinjhwong" target="_blank">
                <img src="images/icons/website_icon.png" alt="website" />
              </a>
            </li>

            <li>
              <a
                href="https://www.linkedin.com/in/kjhwong/"
                target="_blank"
              >
                <img src="images/icons/linked_in_icon.png" alt="linkedin" />
              </a>
            </li>
          </ul>
        </li>
      </ul>
    </section>
  </body>
</html>
